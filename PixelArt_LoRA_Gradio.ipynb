{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0hi-BiDx6cz"
      },
      "source": [
        "# üñºÔ∏è 16x16 Pixel Art Items LoRA - Gradio Interface\n",
        "\n",
        "Before running ensure to change the runtime to a T4 GPU.\n",
        "\n",
        "To run, simply press the play button on the left side of each code block. The process can take 5-10 minutes to install everything.\n",
        "\n",
        "\n",
        "After running the last block, a gradio link will appear which will take you to the interface to generate your art."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCqJd1zu8CgA"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi #Should show GPU info, if you're on T4 GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuVS-UcZyAgq"
      },
      "source": [
        "## Dependencies/SetUp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxA4APfnALF8"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade gradio\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ln4C_K5B1bX"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/huggingface/diffusers\n",
        "# !pip install /content/diffusers\n",
        "!pip install diffusers\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bw7lGaFdFDPb"
      },
      "outputs": [],
      "source": [
        "!accelerate config default --mixed_precision 'fp16'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1cMeekXv396"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/Jhr-4/PixelArt_LoRA/raw/main/16x16_lora.safetensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBq7jnpHyPv3"
      },
      "source": [
        "## Load Base Model: SD v1.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swuXeCglpvN7"
      },
      "outputs": [],
      "source": [
        "model_name = 'stable-diffusion-v1-5/stable-diffusion-v1-5'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PUt4o9iFxIF"
      },
      "outputs": [],
      "source": [
        "pipe = StableDiffusionPipeline.from_pretrained(model_name, torch_dtype=torch.float16)\n",
        "pipe.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiGQP4xEyfwU"
      },
      "source": [
        "## Gradio Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kO2I1uFaAW9c"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "pipe.safety_checker = None #16x16 pixel outputs were getting flagged incorrectly.\n",
        "\n",
        "def generate(prompt, steps, guidance):\n",
        "  if not prompt.strip():\n",
        "    return None, None\n",
        "\n",
        "  LoRA_gallery = []\n",
        "  base_gallery = []\n",
        "\n",
        "  pipe.load_lora_weights(\"/content/16x16_lora.safetensors\")\n",
        "\n",
        "  generated = pipe(f\"min3craft, {prompt}\", num_inference_steps=steps, guidance_scale=guidance, height=256, width=256, num_images_per_prompt=4).images #min3craft is style trigger\n",
        "  for i in generated:\n",
        "      pixelated = i.resize((16,16), Image.NEAREST)\n",
        "      scaledPreview = pixelated.resize((256,256), Image.NEAREST)\n",
        "      LoRA_gallery.append(scaledPreview)\n",
        "\n",
        "\n",
        "\n",
        "  pipe.unload_lora_weights()\n",
        "\n",
        "  generated = pipe(f\"min3craft, {prompt}\", num_inference_steps=steps, guidance_scale=guidance, height=256, width=256, num_images_per_prompt=4).images\n",
        "  for i in generated:\n",
        "      pixelated = i.resize((16,16), Image.NEAREST)\n",
        "      scaledPreview = pixelated.resize((256,256), Image.NEAREST)\n",
        "      base_gallery.append(scaledPreview)\n",
        "\n",
        "\n",
        "  return LoRA_gallery, base_gallery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_tf14fv0s8-"
      },
      "outputs": [],
      "source": [
        "with gr.Blocks() as interface:\n",
        "\n",
        "  gr.Markdown(\"## üñºÔ∏è 16x16 Pixel Art Items LoRA\")\n",
        "  with gr.Accordion(\"‚ú® | Additional Info & Tips\", open=False):\n",
        "    gr.Markdown(\"\"\"\n",
        "      Generate by entering a propmt and clicking generate. Items can be easily isolated by removing the background.\n",
        "      For best results, specify the object, color, and cateogry in a comma-separated list. Additionally, adjust the steps and guidance scale.\n",
        "      Example: \"diamond helmet, blue, armor\"\n",
        "\n",
        "      - **Steps:** The iterations the model takes to produce the output (Lower = faster, but noisey; Higher = slower, but potentially higher quality)\n",
        "      - **Guidance Scale:** Controls how strongly the prompt is followed (Lower = prompt can be ignored; Higher = less creativity)\n",
        "\n",
        "      **Challenges/Limitations:**\n",
        "      - Due to the small size of the dataset, some items won't turn out well\n",
        "      - White items may not generate well due to training on white backgrounds\n",
        "      - Current use case is limited to 2d item generation like game assets\n",
        "      \"\"\")\n",
        "\n",
        "  with gr.Row():\n",
        "    with gr.Column():\n",
        "      LoRA_gallery = gr.Gallery(label=\"LoRA Images\", interactive=False)\n",
        "    with gr.Column():\n",
        "      base_gallery = gr.Gallery(label=\"Base SD 1.5 Images\", interactive=False)\n",
        "\n",
        "  with gr.Row():\n",
        "    with gr.Column(scale=1):\n",
        "      prompt = gr.Textbox(label=\"Prompt\", placeholder=\"e.g., chair, wooden\")\n",
        "      generate_button = gr.Button(\"Generate\", variant=\"primary\")\n",
        "\n",
        "    with gr.Column():\n",
        "      steps = gr.Slider(minimum=1, maximum=100, step=1, value=50, label=\"Steps\")\n",
        "      guidance = gr.Slider(minimum=1, maximum=20, step=0.1, value=7.5, label=\"Guidance Scale\")\n",
        "\n",
        "\n",
        "  generate_button.click(\n",
        "    fn=generate,\n",
        "    inputs=[prompt, steps, guidance],\n",
        "    outputs=[LoRA_gallery, base_gallery],\n",
        "    queue=True\n",
        "    )\n",
        "\n",
        "interface.launch()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
